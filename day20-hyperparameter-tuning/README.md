# âš™ï¸ Day 20 â€“ Hyperparameter Tuning: Grid Search vs Random Search  
ğŸ” #DailyMLDose | ğŸš€ Model Optimization Made Simple

Welcome to **Day 20** of #DailyMLDose!  
Today, we master the art of **Hyperparameter Tuning** â€” a key step in ML model performance.  
We'll break down the two most common methods: **Grid Search** and **Random Search**, with **visuals and live code**.

---
ğŸ“‚ Project Folder Structure
```
day20-hyperparameter-tuning/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ grid_search_demo.py
â”‚   â””â”€â”€ random_search_demo.py
â”‚
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ grid_vs_random_search_diagram.png
â”‚   â”œâ”€â”€ grid_search_explained.png
â”‚   â”œâ”€â”€ random_search_explained.png
â”‚   â””â”€â”€ hyperparameter_tuning_visuals.png
â””â”€â”€ README.md
```
---

## ğŸ“Œ What is Hyperparameter Tuning?

**Hyperparameters** are the settings that control the behavior of your ML algorithm â€” but they are **not learned from the data**. You set them manually or through tuning.

### ğŸ¯ Common Hyperparameters:
- ğŸ§  Learning rate  
- ğŸŒ³ `max_depth` (tree models)  
- ğŸ“ˆ `C`, `gamma` (SVM)  
- ğŸ `n_estimators` (ensemble models)

Tuning helps you find the **best combination** to **maximize validation accuracy** and generalize better.

---

## âš”ï¸ Grid Search vs Random Search â€“ A Visual Comparison

| ğŸ” Method         | ğŸ“– Description                                 | âœ… Pros                          | âš ï¸ Cons                        |
|------------------|------------------------------------------------|----------------------------------|-------------------------------|
| **ğŸ§± Grid Search**   | Exhaustively tries **all combinations**         | ğŸ¯ Systematic & reproducible      | ğŸŒ Very slow for large spaces  |
| **ğŸ² Random Search** | Samples a **fixed number** of random combos   | âš¡ Faster, covers wide areas      | ğŸ¯ May miss the best combo     |

---

## ğŸ–¼ï¸ Visual Intuition

> These diagrams will help you **visually grasp** how Grid and Random Search explore parameter space.

<div align="center">

![Grid vs Random Diagram](images/grid_vs_random_search_diagram.png)  
â¬†ï¸ *Grid systematically covers all points, Random spreads out faster across the space.*

---

![Grid Search Explained](images/grid_search_explained.png)  
ğŸ“Š *Exhaustive search across all combinations.*

---

![Random Search Explained](images/random_search_explained.png)  
ğŸ¯ *Random picks from ranges â€” less computation, still effective.*

---

![Tuning Overview](images/hyperparameter_tuning_visuals.png)  
ğŸ§  *Complete visual of the tuning process and its impact.*

</div>

---

## ğŸ’» Code Demos â€“ Try It Yourself!

### ğŸ§© Grid Search (Exhaustive)

```python
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV

# Load data
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# Define parameter grid
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 10]
}

# Grid Search
model = RandomForestClassifier()
grid = GridSearchCV(model, param_grid, cv=5)
grid.fit(X_train, y_train)

print("Best Params from GridSearch:", grid.best_params_)
```
ğŸ² Random Search (Efficient Sampling)

```
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint

# Random param distributions

param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 20)
}

# Random Search
random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5)
random_search.fit(X_train, y_train)

print("Best Params from RandomSearch:", random_search.best_params_)
```
ğŸ§  TL;DR Summary
âœ… When to Use	ğŸš€ Recommendation
Grid Search	Small search space & you want full coverage
Random Search	Large space or you want fast results

âœ”ï¸ Always use cross-validation to prevent overfitting during tuning.

ğŸ§ª Use libraries like GridSearchCV and RandomizedSearchCV from sklearn.


ğŸ” Previous Post
ğŸ“Œ [Day 19 â†’ Feature Importance.](../day19-feature-importance)

Intuition Videos: @statquest, @learn_ml_daily

ğŸ™Œ Stay Connected
- ğŸ”— [Follow Shadabur Rahaman on LinkedIn](https://www.linkedin.com/in/shadabur-rahaman-1b5703249)
â­ Star the GitHub Repo
ğŸ’¬ Letâ€™s keep fine-tuning our knowledge â€” one parameter at a time!

